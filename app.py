import google.generativeai as genai
import PyPDF2
import os
from flask import Flask, request, jsonify
from sentence_transformers import SentenceTransformer
import numpy as np

# ================== Flask ==================
app = Flask(__name__)

# ================== Embedding Model ==================
embed_model = SentenceTransformer(
    "paraphrase-multilingual-MiniLM-L12-v2"
)

# ================== Gemini API ==================
genai.configure(api_key=os.getenv("AIzaSyDsYHpZEbjkq1Fp-gbPTkaSi3bb7Hx5Kh4"))
model = genai.GenerativeModel("gemini-3-flash-preview")
chat = model.start_chat(history=[])

# ================== PDF PATH ==================
PDF_PATH = os.path.join(os.path.dirname(__file__), "scout.pdf")

# ================== Load PDF ==================
def load_pdf_chunks(path, chunk_size=800):
    text = ""
    with open(path, "rb") as file:
        reader = PyPDF2.PdfReader(file)
        for page in reader.pages:
            if page.extract_text():
                text += page.extract_text() + "\n"

    chunks = []
    current = ""
    for line in text.split("\n"):
        current += line + " "
        if len(current) >= chunk_size:
            chunks.append(current.strip())
            current = ""
    if current.strip():
        chunks.append(current.strip())

    return chunks

try:
    pdf_chunks = load_pdf_chunks(PDF_PATH)
    print("PDF Loaded:", len(pdf_chunks))
except Exception as e:
    print("PDF ERROR:", e)
    pdf_chunks = []

# ================== Embeddings ==================
if pdf_chunks:
    chunk_embeddings = embed_model.encode(
        pdf_chunks, normalize_embeddings=True
    )
else:
    chunk_embeddings = np.array([])

def semantic_search(question, chunks, embeddings, top_k=5):
    if embeddings.size == 0:
        return []

    q_vec = embed_model.encode(
        [question], normalize_embeddings=True
    )[0]
    scores = np.dot(embeddings, q_vec)
    top_indices = np.argsort(scores)[-top_k:][::-1]
    return [chunks[i] for i in top_indices if scores[i] > 0.2]

# ================== Keyword Search ==================
def normalize_text(text):
    stop_words = [
        "Ù…Ø§", "Ù‡Ùˆ", "Ù‡ÙŠ", "Ù…Ù†", "Ø¹Ù†",
        "Ø£Ù†ÙˆØ§Ø¹", "Ø§Ø°ÙƒØ±", "Ø¹Ø±Ù", "ØªØ¹Ø±ÙŠÙ"
    ]
    words = text.replace("ØŸ", "").split()
    return [w for w in words if w not in stop_words]

synonyms = {
    "Ø£Ù†ÙˆØ§Ø¹": ["ØªÙ†Ù‚Ø³Ù…", "ØªØµÙ†Ù"],
    "Ù…Ø¤Ø³Ø³": ["Ø£Ù†Ø´Ø£", "Ù…Ø¤Ø³Ø³ Ø§Ù„Ø­Ø±ÙƒØ©"],
    "ÙˆØ§Ø¬Ø¨Ø§Øª": ["ÙŠÙ„ØªØ²Ù…", "Ù…Ø³Ø¤ÙˆÙ„ÙŠØ§Øª"],
    "ÙˆØ¹Ø¯": ["ÙŠØªØ¹Ù‡Ø¯", "Ø§Ù„ØªØ¹Ù‡Ø¯"],
}

def expand_keywords(words):
    expanded = set(words)
    for w in words:
        if w in synonyms:
            expanded.update(synonyms[w])
    return expanded

def find_relevant_chunks(question, chunks, max_chunks=5):
    keywords = expand_keywords(normalize_text(question))
    scored_chunks = []

    for chunk in chunks:
        score = 0
        for word in keywords:
            if word in chunk:
                score += chunk.count(word) * 2
        if score > 0:
            scored_chunks.append((score, chunk))

    scored_chunks.sort(key=lambda x: x[0], reverse=True)
    return [c[1] for c in scored_chunks[:max_chunks]]

# ================== API Endpoint ==================
@app.route("/chat", methods=["POST"])
def chat_api():
    data = request.json
    user_input = data.get("message", "").strip()

    if not user_input:
        return jsonify({"reply": "âš ï¸ Ù…Ù† ÙØ¶Ù„Ùƒ Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ù‹Ø§"})

    if not pdf_chunks:
        return jsonify({"reply": "âŒ Ù„Ù… ÙŠØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù†Ù‡Ø¬."})

    relevant_text = semantic_search(
        user_input, pdf_chunks, chunk_embeddings
    )

    if not relevant_text:
        relevant_text = find_relevant_chunks(
            user_input, pdf_chunks
        )

    if not relevant_text:
        return jsonify({
            "reply": "âš ï¸ Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø© ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ Ø§Ù„Ù…Ù†Ù‡Ø¬."
        })

    prompt = f"""
Ø£Ù†Øª Ù…Ø¯Ø±Ø³ ÙƒØ´Ø§ÙØ© Ø®Ø¨ÙŠØ±.
Ù…Ù‡Ù…ØªÙƒ Ø´Ø±Ø­ Ø§Ù„Ù…Ù†Ù‡Ø¬ Ù„Ù„Ø·Ù„Ø§Ø¨.

ğŸ“˜ Ù†Øµ Ù…Ù† Ø§Ù„Ù…Ù†Ù‡Ø¬:
{' '.join(relevant_text)}

â“ Ø³Ø¤Ø§Ù„ Ø§Ù„Ø·Ø§Ù„Ø¨:
{user_input}

ğŸ“Œ Ù‚ÙˆØ§Ø¹Ø¯ ØµØ§Ø±Ù…Ø©:
- Ø£Ø¬Ø¨ Ù…Ù† Ø§Ù„Ù†Øµ ÙÙ‚Ø·
- Ù„Ø§ ØªØ¶Ù Ø£ÙŠ Ù…Ø¹Ù„ÙˆÙ…Ø© Ø®Ø§Ø±Ø¬ Ø§Ù„Ù…Ù†Ù‡Ø¬
- Ø§ÙƒØªØ¨ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø£ÙˆÙ„Ù‹Ø§ ÙƒÙ…Ø§ ÙˆØ±Ø¯Øª ÙÙŠ Ø§Ù„Ù…Ù†Ù‡Ø¬
- Ø¨Ø¹Ø¯Ù‡Ø§ Ù‚Ø¯Ù‘Ù… Ø´Ø±Ø­Ù‹Ø§ Ù…Ø¨Ø³Ø·Ù‹Ø§ Ù„Ù„Ø·Ø§Ù„Ø¨
- Ù„Ùˆ Ù„Ù… ØªØ¬Ø¯ Ø¥Ø¬Ø§Ø¨Ø© ÙˆØ§Ø¶Ø­Ø© Ù‚Ù„:
âš ï¸ Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø© ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ Ø§Ù„Ù…Ù†Ù‡Ø¬
- Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙÙ‚Ø·
"""

    try:
        response = chat.send_message(prompt)
        return jsonify({"reply": response.text})
    except Exception as e:
        return jsonify({"reply": f"âŒ Ø®Ø·Ø£: {e}"})


if __name__ == "__main__":
    app.run(debug=True)
